- load content from excel file as streaming data 
- After we get streaming data we convert into byteArray 


filePart.content() // Flux<DataBuffer> 
			.map(dataBuffer -> {
				return null;
			});

==> áá¶á˜ášá™áŸˆ dataBuffer á“á¹á„á™á¾á„á”á„áŸ’á€á¾á Byte Array    

ğŸ“¦ What Is a Data Buffer?
A data buffer is a temporary storage area in memory used to hold chunks of data while it's being transferred from one place to anotherâ€”like from a user's device to a server.

ğŸ§  Why Use a Buffer for File Uploads?
When uploading a file, especially large ones, you don't usually read the entire file into memory at once. Instead, you:
- Read the file in small chunks (buffers)
- Process or store each chunk
- Repeat until the entire file is uploaded
This approach is efficient, scalable, and prevents memory overload


Ex:

- byte[] bytes = new byte[dataBuffer.readableByteCount()]; á˜á¶á“á“áŸá™áá¶áœá¶á˜á¶á“áŸá˜ááŸ’áá·á—á¶á–á•áŸ’á‘á»á€á‘áŸ…áá¶á˜ buffer áŠáŸ‚á›áœá¶ Store á“á¹á„á á¾á™ ááŸ‚áœá¶á˜á·á“á‘á¶á“áŸ‹á˜á¶á“ Data á¢á¸á˜á€á‘áŸ

==> so we need to read the data from the databuffer (á˜á¶á“á“áŸá™áá¶ á™á¾á„ read á–á¸áš dataBuffer á…á¼á›á‘áŸ…á€áŸ’á“á»á„ â€‹byte[] ášá”áŸáŸ‹á™á¾á„áŸ”â€‹

- dataBuffer.read(bytes);

á™á¾á„ Read á”á¶á“á á¾á™á™á¾á„ clean data á“á¹á„áœá·á‰ á á¾á™á˜á½á™á‡á»áŸ† áŸ—áœá¶ read data á“á¹á„á¡á¾á„áœá·á‰ ==> then we return it to the data stream 

--------------------------------

We read file from excel : mean we want to convert from the excel to byte and it need to have streaming 

Workbook workbook = new XSSFWorkbook(null) áœá¶ááŸ’ášá¼áœá€á¶áš Input stream á…á¹á„áá¶á„á›á¾ dataBuffer.read(bytes);

We need to convert to input stream 

------------------------------
Step by Step 

1. First we need to convert from byte array to input stream 
2. after we get the inpute stream let other do it 

======================

1- First part : convert from byte array to input stream 

@Override
	public Mono<RoomImportSummary> importRooms(FilePart filePart) {
		
		return filePart.content() // Flux<DataBuffer> 
			.map(dataBuffer -> {
				byte[] bytes = new byte[dataBuffer.readableByteCount()];
				dataBuffer.read(bytes); // we read data from databuffer and store in byte[] 
				
				// we need to have one operation to protech memory lead (clean up memory)
				
				DataBufferUtils.release(dataBuffer);
				
				return new ByteArrayInputStream(bytes);				
				// after return we get the byte array input stream 
			})
			.next() // when we get one buffer we want to save to our database ==> create another to save 			
			.flatMap(inputStream -> parseAndSaveRooms(inputStream));
		
		
	}

2- parseAndSaveRooms

- we create batch id // to define with batch have issue 
- create work book 
Workbook workbook = new XSSFWorkbook(inputStream); it will have check exception 

---------------------------------------------

try {
			Workbook workbook = new XSSFWorkbook(inputStream);
		} catch (IOException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}

---------------------------

this is our normal try catch ==> we use try with resource to clean up the data for us 

==> 

- in the workbook it have sheet => we want to catch first sheet 


			 // we want to return our roomSummary 
			 // save have two condition : good save to room and not good save to Skip room 
			List<Room> validRoom = new ArrayList<>();
			List<Integer> skippedRow = new ArrayList<>();
			Map<Integer, String> reasons = new HashMap<>();
			
			// error happend we keep in one list 			
			List<SkippedRoomDocument> skippedRoomDocuments = new ArrayList<>();


==> á–áŸá›áŠáŸ‚á›á™á¾á„á…á¶á”áŸ‹á”á¶á“ sheet in excel á á¾á™ á™á¾á„á…á„áŸ‹ášá¶á”áŸ‹á…áŸ†á“á½á“ row á…á¹á„á™á¾á„á¢á¶á…á”áŸ’ášá¾ looping ban 
we want to loop each row by row : 

==> Solution we want to build first with our collection : good List and bad List after that we save to database. we do this it will save database access many time. 

==> if we make access to many to database it will lateancey that make our system slow. not good performance 

áá¶á˜ášá™áŸˆ á˜áŸ‰á¶ Row á“á¹á„á™á¾á„á”á¶á“ á˜áŸ‰á¶ cell 

Row row = sheet.getRow(i);

----------------------------------------------------------------------------------------- 

- We want to build the object that save the SkippedRoomDocument :

private SkippedRoomDocument buildSkippedRoomDocument(int rowNumber, 
			Map<String, Object> rowData, String reason, String uploadBatchId) {
		
		
		return null;
	}

There two ways to create objects : use New to create object and with @builder in Lombok to create object 

==> 

@Data
@Builder
@Document(collation = "skipped_rooms")
public class SkippedRoomDocument {
	
	@Id
	private String id;
	
	private int rowNumber; // wich row it error 
	
	private Map<String, Object> rowData; // we capture 
	
	private String reason; // what is the reason 
	private LocalDateTime uploadDate;
	private String uploadBatchId; // number of batch that we upload

}

@builder : it is easy to create object one by one field and it not thinking the order 















































































































